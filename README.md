# 2025ESWcontest_I_hate_bend_down

# 자동 신발 정리 로봇 (Automatic Shoe Organizer Robot)

**"누구나 숙이지 않고도 깨끗하고 질서 있는 현관을 누릴 수 있게 하자."**

이 프로젝트는 거동이 불편하신 조부모님께서 매일 현관의 신발을 정리하시는 모습에서 영감을 받아 시작되었습니다. 반복적으로 허리를 숙이는 동작이 관절에 주는 부담을 로봇으로 해결하고자, **AI 비전 시스템**과 **라인트레이서 로봇**을 결합한 자동 신발 정리 시스템을 개발했습니다.


## 📝 프로젝트 개요 (Overview)

본 시스템은 천장에 설치된 카메라로 신발의 위치를 인식하고, 로봇이 격자무늬 바닥의 라인을 따라 이동하여 신발을 지정된 위치로 옮기는 방식으로 동작합니다. 고가의 LiDAR나 SLAM 기술 대신, 카메라와 간단한 격자 바닥을 사용하여 비용 효율성과 높은 반복 정밀도를 동시에 달성했습니다.

* **AI 비전 시스템 (Python)**: 웹캠으로 현관을 촬영하여 YOLOv8 모델로 신발을 탐지합니다. Homography(원근 변환) 기술을 이용해 카메라 시점의 2D 이미지 좌표를 실제 바닥의 격자 좌표로 변환합니다.
* **자율주행 로봇 (Arduino)**: AI 시스템으로부터 블루투스로 목표 좌표를 전달받습니다. 적외선 센서로 바닥의 라인을 따라 주행하며, 교차점을 지날 때마다 자신의 위치를 갱신하여 목표 지점까지 정확하게 이동합니다. 목표 지점에 도달하면 서보 모터로 제어되는 그리퍼로 신발을 집어 옮깁니다.

## ✨ 주요 기능 (Key Features)

* **AI 기반 객체 탐지**: YOLOv8 모델을 활용하여 실시간으로 신발을 탐지합니다.
* **원근 왜곡 보정**: Homography 기술로 카메라 왜곡을 보정하여 이미지 속 좌표를 실제 바닥 좌표로 정밀하게 매핑합니다.
* **격자 기반 자율주행**: 복잡한 맵핑 없이 격자무늬 라인과 교차점을 기준으로 위치를 추적하며 안정적으로 주행합니다 (`navigation.cpp`).
* **모듈화된 제어 시스템**: 모터 제어 (`dc_motor`), 라인 트레이싱 (`line_trace`), 위치 및 경로 관리 (`navigation`), 블루투스 통신 (`bt_command`), 그리퍼 동작 (`servo_grip`) 등 기능별로 코드가 모듈화되어 유지보수가 용이합니다.
* **블루투스 통신**: AI 시스템과 로봇 간의 명령(목표 좌표) 및 상태(현재 위치)를 무선으로 주고받습니다.

## 🛠️ 하드웨어 구성 (Hardware)

| 부품                      | 역할                                       | 관련 소스                                 |
| ------------------------- | ------------------------------------------ | ----------------------------------------- |
| **AI 연산부** |                                            |                                           |
| PC / 노트북               | YOLOv8 및 OpenCV 연산 수행                 | `개발개요서v1.pdf`               |
| 웹캠                      | 현관 바닥 영상 실시간 촬영                 | `개발개요서v1.pdf`               |
| **로봇 본체** |                                            |                                           |
| Arduino Uno               | 로봇의 모든 센서와 액추에이터 제어         | `개발개요서v1.pdf`               |
| 4WD RC카 섀시             | 4륜 구동 DC 모터 기반 이동 플랫폼          | `dc_motor.h`, `dc_motor.cpp`              |
| TCRT5000 IR 센서 x 4      | 바닥의 라인 및 교차점 감지                 | `line_trace.h`                  |
| MG995 서보 모터           | 신발을 집고 놓는 그리퍼(집게) 작동         | `servo_grip.h`, `servo_grip.cpp`  |
| 블루투스 모듈 (HC-06 등)  | AI 시스템과 무선 시리얼 통신             | `bt_command.h`                            |
| 18650 배터리 x 2          | 로봇 구동 전원 공급                        | `개발개요서v1.pdf`                |

## 💻 소프트웨어 및 라이브러리 (Software & Libraries)

* **🤖 로봇 (Arduino)**
    * **개발 환경**: Arduino IDE
    * **언어**: C/C++
    * **주요 라이브러리**: `Servo.h`, `NeoSWSerial.h`

* **🧠 AI 시스템 (PC)**
    * **개발 환경**: PyCharm, Roboflow 
    * **언어**: Python 3.9 
    * **핵심 라이브러리**:
        * `Ultralytics YOLOv8`: 실시간 신발 탐지
        * `OpenCV`: 이미지 처리 및 원근 변환 
        * `NumPy`: 좌표 및 행렬 연산

## 📂 소스 코드 설명 (Source Code)

### Arduino (`.ino`, `.cpp`, `.h`)

* `test_btcommand.ino`: 메인 실행 파일. `setup()`에서 각 모듈을 초기화하고, `loop()`에서 블루투스 명령을 받아 해당 기능을 실행합니다.
* `dc_motor`: 4륜 DC 모터의 전진, 후진, 회전, 정지 등 저수준 제어 함수를 제공합니다.
* `line_trace`: IR 센서 값을 읽어 라인을 따라 주행하고, 교차점을 감지하는 핵심 주행 알고리즘을 담당합니다. 일반 모드(`line_trace`)와 토크 모드(`line_trace_torque`)를 지원합니다.
* `navigation`: 로봇의 현재 좌표(x, y)와 방향(NORTH, EAST, SOUTH, WEST)을 관리합니다. `move_to_position()` 함수를 통해 목표 좌표까지의 경로를 생성하고 이동을 제어합니다.
* `bt_command`: 블루투스로 수신된 문자열을 파싱하여 `CMD_FORWARD`, `CMD_MOVE_TO` 등 사전 정의된 명령(enum)으로 변환합니다. `(x,y)` 형태의 좌표 명령도 해석할 수 있습니다.
* `servo_grip`: 그리퍼를 열고(`openGrip`) 닫는(`closeGrip`) 기능을 부드러운 움직임으로 구현합니다.
* `motor_balance.h`: 모터의 좌우 출력 차이를 미세 조정하여 직선 주행 성능을 보정합니다.

### AI System (`.py`)

* `live_calibration.py`: 실제 바닥의 격자 모서리와 카메라 영상의 픽셀을 매칭시켜 원근 변환 행렬(`homography_matrix.npy`)을 생성하는 보정 스크립트입니다.
* `grid_angle_detector.py`: `live_calibration.py`로 생성된 행렬을 이용해 YOLO로 탐지한 신발의 픽셀 좌표를 실제 격자 좌표로 변환하고, 가장 가까운 교차점과 접근 방향을 계산하는 핵심입니다.
* `smart_notification_sender.py`: 최종 실행 파일로, 신발이 특정 시간 동안 같은 위치에 머무는 등 복합 조건을 판단하여 로봇에게 이동 명령을 전송하는 로직을 포함합니다.

## 🚀 동작 순서 (Workflow)

1.  **초기화**: 사용자는 AI 프로그램의 `live_calibration.py`를 실행하여 카메라 시점을 보정합니다.
2.  **탐지 및 좌표 변환**: AI 메인 프로그램이 웹캠 영상을 받아 YOLOv8로 신발을 탐지합니다. 탐지된 신발의 위치는 원근 변환 행렬을 통해 실제 바닥의 `(x, y)` 좌표로 변환됩니다.
3.  **명령 전송**: 계산된 좌표 `(x, y)`는 블루투스를 통해 Arduino 로봇으로 전송됩니다.
4.  **명령 수신 및 경로 계획**: 로봇은 `bt_checkCommand()`를 통해 `(x, y)` 좌표를 수신하고, `navigation` 모듈은 현재 위치에서 목표 지점까지의 경로(Y축 우선 이동, 이후 X축 이동)를 계획합니다.
5.  **자율 주행**: 로봇은 `line_trace()` 함수를 호출하여 라인을 따라 한 칸씩 이동합니다. 교차점에 도달할 때마다 `update_position()`으로 자신의 좌표를 갱신합니다.
6.  **방향 전환**: 경로에 따라 방향을 바꿔야 할 경우, `adjust_direction()` 함수가 `turn_left()` 또는 `turn_right()`를 호출하여 90도 회전하고 `update_direction()`으로 현재 방향을 갱신합니다.
7.  **작업 수행 및 복귀**: 목표 좌표에 도달하면 그리퍼를 이용해 신발을 집거나 내려놓는 동작을 수행하고, 초기 위치 `(0, 0)`으로 복귀합니다.

---
